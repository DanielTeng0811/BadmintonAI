import pandas as pd
import numpy as np
import sqlite3
import os

def process_badminton_data(input_source, output_csv_path="processed_new_3.csv", output_db_path="processed_new_3.db"):
    """
    Processes raw badminton match data and saves it to CSV and SQLite.
    
    Args:
        input_source: File path (str) or DataFrame containing the raw data.
        output_csv_path: Path to save the processed CSV.
        output_db_path: Path to save the processed SQLite database.
        
    Returns:
        pd.DataFrame: The processed DataFrame.
    """
    
    # 1. Load Data
    if isinstance(input_source, pd.DataFrame):
        df = input_source.copy()
    else:
        # Assume it's a file path or file-like object (e.g. Streamlit UploadedFile)
        try:
            df = pd.read_csv(input_source)
        except Exception as e:
             raise ValueError(f"Input source must be a file path, file-like object, or DataFrame. Error: {e}")

    print("ğŸš€ é–‹å§‹è™•ç†è³‡æ–™...")

    # Step 1. ç§»é™¤ type ç‚º "æ¥ä¸åˆ°" çš„åˆ—
    initial_len = len(df)
    df = df[df['type'] != 'æ¥ä¸åˆ°']
    print(f"âœ… å·²ç§»é™¤ 'æ¥ä¸åˆ°' çš„è³‡æ–™ (ç§»é™¤ {initial_len - len(df)} ç­†)")

    # å»ºç«‹é®ç½©è™•ç† getpoint_player
    # é‚è¼¯: åªæœ‰æ¯å€‹ rally çš„æœ€å¾Œä¸€çƒæ‰æ‡‰è©²æœ‰ getpoint_playerï¼Œå…¶é¤˜è¨­ç‚º NaN
    mask_not_last_in_rally = df.duplicated(subset=['rally_id'], keep='last')
    df.loc[mask_not_last_in_rally, 'getpoint_player'] = np.nan
    print("âœ… 'getpoint_player' è™•ç†å®Œç•¢ã€‚")

    # Step 2. è‹¥ lose_reason æˆ– win_reason åŒ…å«ã€Œå°æ‰‹ã€å‰‡æ”¹ç‚º NaN
    for col in ['lose_reason', 'win_reason']:
        if col in df.columns:
            df[col] = df[col].apply(lambda x: np.nan if isinstance(x, str) and "å°æ‰‹" in x else x)

    # --- [New] Rename Columns Early ---
    # ç‚ºäº†è®“å¾ŒçºŒçš„ score æ›´æ–°å¯ä»¥ç›´æ¥å°æ‡‰åˆ°çƒå“¡åç¨±ï¼Œæˆ‘å€‘å…ˆé€²è¡Œæ¬„ä½é‡æ–°å‘½å
    p1_name = None
    p2_name = None
    if not df.empty:
        try:
            # å‡è¨­ç¬¬ä¸€ç­†è³‡æ–™çš„ player æ˜¯ä¸»è§’ï¼Œopponent æ˜¯å°æ‰‹ (è‹¥ opponent æ¬„ä½å°šæœªå­˜åœ¨ï¼Œéœ€å…ˆæ¨æ–·)
            # å› ç‚º opponent æ¬„ä½æ˜¯åœ¨ loop ä¸­å»ºç«‹çš„ï¼Œé€™è£¡æˆ‘å€‘å…ˆæƒæ player æ¬„ä½
            unique_players = df['player'].dropna().unique()
            if len(unique_players) >= 2:
                # ç°¡å–®å‡è¨­å‰å…©å€‹å°±æ˜¯é›™æ–¹
                p1_name = df.iloc[0]['player'] # ç¶­æŒåŸ data_loader é‚è¼¯ï¼Œç¬¬ä¸€ç­†ç‚ºåŸºæº–
                # æ‰¾å‡ºå¦ä¸€å€‹
                p2_name = next((p for p in unique_players if p != p1_name), None)
                
                if p1_name and p2_name:
                    rename_map = {
                        'player_score': f'{p1_name}_score',
                        'opponent_score': f'{p2_name}_score'
                    }
                    # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨ (é¿å…å¤šæ¬¡æ›´åå¤±æ•—)
                    if 'player_score' in df.columns:
                        df = df.rename(columns=rename_map)
                        print(f"âœ… [Pre-process] å·²å°‡åˆ†æ•¸æ¬„ä½å‘½å: {rename_map}")
        except Exception as e:
            print(f"âš ï¸ Pre-process renaming failed: {e}")

    # Step 3. æ¯å ´æ¯”è³½çš„æ¯å€‹ set æœ€å¾Œæ’å…¥ä¸€ç­†æ–°è³‡æ–™ï¼Œä¸¦æ–°å¢ opponent æ¬„ä½
    # ----------------------------------------------------
    dfs_to_concat = []

    # ç¢ºä¿å¿…è¦çš„æ¬„ä½å­˜åœ¨
    required_cols = ['match_id', 'set', 'player']
    if not all(col in df.columns for col in required_cols):
         raise ValueError(f"è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½: {required_cols}")

    # åˆ†çµ„ï¼šæ¯å ´æ¯”è³½ + è©²æ¯”è³½çš„æ¯å€‹ set
    for (match_id, set_id), group in df.groupby(['match_id', 'set'], sort=False):
        group = group.copy()

        # --- è™•ç† opponent æ¬„ä½ ---
        players = group['player'].dropna().unique()
        if len(players) == 2:
            p1, p2 = players[0], players[1]
            opponent_map = {p1: p2, p2: p1}
            group['opponent'] = group['player'].map(opponent_map)
        else:
            group['opponent'] = np.nan
        
        # åŠ å…¥åŸå§‹è³‡æ–™
        dfs_to_concat.append(group)

        # è™•ç†æœ€å¾Œä¸€ç­† & åŠ åˆ†
        try:
            last_row = group.iloc[-1].copy()
            winner = last_row.get('getpoint_player')
            
            if pd.notna(winner):
                # [User Request]: æ ¹æ“š winner æ˜¯èª°è®“ {name}_score æ¬„ä½ +1
                score_col = f"{winner}_score"
                
                if score_col in last_row:
                    try:
                        last_row[score_col] = float(last_row[score_col]) + 1
                    except:
                         last_row[score_col] = 1.0 # è‹¥åŸæœ¬ NaN æˆ–éæ•¸å€¼
                else:
                    # Fallback: å¦‚æœæ‰¾ä¸åˆ° {winner}_scoreï¼Œå¯èƒ½æ˜¯åç¨±æ¯”å°å•é¡Œ
                    # å˜—è©¦æ¯”å° player/opponent
                     current_player = last_row['player']
                     current_opponent = last_row.get('opponent')
                     
                     # å˜—è©¦æ‰¾å°æ‡‰çš„ score column
                     # æ³¨æ„ï¼šæ­¤æ™‚ columns å·²ç¶“è¢« rename æˆ Name_score äº†
                     # æ‰€ä»¥ last_row['player_score'] å¯èƒ½ä¸å­˜åœ¨
                     
                     # è‹¥ winner == current_player, update that player's score column
                     # But we need to know WHICH column that is.
                     # Since we renamed 'player_score' -> 'P1_score', we need to check if current_player is P1.
                     
                     # æ¯”è¼ƒå®‰å…¨çš„åšæ³•: éæ­·æ‰€æœ‰ columnsï¼Œçœ‹èª°åƒæ˜¯ score
                     pass
                     print(f"Warning: Score column '{score_col}' not found. Columns: {last_row.index.tolist()}")

                dfs_to_concat.append(pd.DataFrame([last_row]))
        
        except Exception as e:
            print(f"Error processing last row: {e}")
            pass

    # 4. æœ€å¾Œä¸€æ¬¡åˆä½µæ‰€æœ‰è³‡æ–™
    new_df = pd.concat(dfs_to_concat, ignore_index=True)
    
    if 'score_status' in new_df.columns:
        new_df = new_df.drop(columns=['score_status'])
        print("âœ… å·²æˆåŠŸåˆªé™¤ 'score_status' æ¬„ä½ã€‚")
        
    # è¼¸å‡º CSV
    new_df.to_csv(output_csv_path, index=False)
    print(f"âœ… å·²å®Œæˆï¼šè³‡æ–™è™•ç†ä¸¦å„²å­˜è‡³ {output_csv_path}")
    
    # è¼¸å‡º SQLite
    try:
        conn = sqlite3.connect(output_db_path)
        table_name = "match_data"
        new_df.to_sql(table_name, conn, if_exists="replace", index=False)
        conn.close()
        print(f"âœ… å·²å°‡è³‡æ–™åŒ¯å…¥ SQLite è³‡æ–™åº« {output_db_path}")
    except Exception as e:
        print(f"âš ï¸ SQLite åŒ¯å…¥å¤±æ•—: {e}")

    return new_df

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨ï¼šç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆæœƒå˜—è©¦è™•ç† all_dataset.csv
    if os.path.exists("all_dataset.csv"):
        process_badminton_data("all_dataset.csv")
    else:
        print("all_dataset.csv not found for testing.")
