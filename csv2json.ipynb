{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac5f53e",
   "metadata": {},
   "source": [
    "å°‡all_dataset.csvè½‰æ›æˆDBï¼Œè¡¨æ ¼badminton_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67fc6961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV å·²æˆåŠŸå­˜å…¥ SQLite è³‡æ–™åº« data.db çš„ badminton_data è¡¨æ ¼\n",
      "å‰ 5 ç­†è³‡æ–™ï¼š\n",
      "(1, 1, '0:07:39', 11496.0, 0.0, 0.0, 0.0, 'Kento MOMOTA', 1.0, 'ç™¼çŸ­çƒ', 0.0, 1.0, 2.0, 14.0, -0.0196492380571161, 0.3664146155198778, 1.0, 18.0, -0.073337499654345, 0.5945635355250196, None, None, 'Kento MOMOTA', None, 14.0, -0.0196492380571161, 0.3664146155198778, 0.0316904856227849, -0.1035456857115604, 10.0, -0.1632827887015297, 0.285619010735518, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0120412475656688, 0.2628689298083174, None, 0.0, 0.0, 0.0, 1, 1.0, 0)\n",
      "(1, 2, '00:07:43', 11582.0, 0.0, 0.0, 0.0, 'CHOU Tien Chen', 3.0, 'é•·çƒ', 0.0, 1.0, 2.0, 18.0, -0.073337499654345, 0.5945635355250196, 2.0, 32.0, -0.4513914856846306, -0.4228076653977647, 'å‡ºç•Œ', 'å°æ‰‹å‡ºç•Œ', 'Kento MOMOTA', None, 10.0, -0.1632827887015297, 0.285619010735518, 0.0, 0.0, 11.0, 0.0120412475656688, 0.2628689298083174, 0.0316904856227849, -0.1035456857115604, 0.3217714630280202, None, None, 18.0, -0.073337499654345, 0.5945635355250196, None, 0.0899452890471847, 0.3089445247895016, 0.0, 1, 1.0, 0)\n",
      "(2, 1, '0:07:55', 11881.0, 1.0, 1.0, 0.0, 'Kento MOMOTA', 1.0, 'ç™¼çŸ­çƒ', 0.0, 1.0, 2.0, 15.0, 0.0686698043876449, 0.3867684333496436, 2.0, 15.0, 0.2744344201718973, 0.4998572831495475, None, None, 'Kento MOMOTA', None, 15.0, 0.0686698043876449, 0.3867684333496436, -0.0566760594357769, -0.1111039581329691, 11.0, 0.3064756103850713, 0.2890356910072441, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.011993744951868, 0.2756644752166745, None, 0.0, 0.0, 0.0, 1, 1.0, 1)\n",
      "(2, 2, '0:07:56', 11900.0, 1.0, 1.0, 0.0, 'CHOU Tien Chen', 2.0, 'æ¨æ’²çƒ', 0.0, 1.0, 1.0, 15.0, 0.2744344201718973, 0.4998572831495475, 2.0, 7.0, 0.3114890567274725, -0.137782153135466, None, None, 'Kento MOMOTA', None, 11.0, 0.3064756103850713, 0.2890356910072441, -0.33252126646241, -0.3572638515004004, 11.0, 0.011993744951868, 0.2756644752166745, -0.0566760594357769, -0.1111039581329691, 0.213242541683625, 9.0, 1.0, 10.0, -0.0580868462905127, 0.1425934316491471, None, -0.032041190213174, 0.2108215921423034, 0.0, 1, 1.0, 1)\n",
      "(2, 3, '0:07:56', 11921.0, 1.0, 1.0, 0.0, 'Kento MOMOTA', 2.0, 'æ®ºçƒ', 0.0, 0.0, 2.0, 7.0, 0.3114890567274725, -0.137782153135466, 1.0, 10.0, -0.131393895801771, 0.0929926188139302, None, None, 'Kento MOMOTA', None, 11.0, 0.011993744951868, 0.2756644752166745, -0.1529985989639092, 0.1376421933434936, 10.0, -0.0580868462905127, 0.1425934316491471, -0.33252126646241, -0.3572638515004004, 0.5105247851684769, 4.0, 9.0, 7.0, 0.1584904577635633, -0.0001399597919724, None, 0.2994953117756045, -0.4134466283521404, 0.0, 1, 1.0, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# === 1. è®€å– CSV æª”æ¡ˆ ===\n",
    "csv_file = \"all_dataset.csv\"   # ä½ çš„ CSV æª”å\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# === 2. å»ºç«‹æˆ–é€£ç·š SQLite è³‡æ–™åº« (æœƒå»ºç«‹ data.db æª”æ¡ˆ) ===\n",
    "db_file = \"data.db\"\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "# === 3. å°‡ CSV å­˜æˆä¸€å¼µè¡¨æ ¼ ===\n",
    "table_name = \"badminton_data\"   # è‡ªè¨‚è¡¨æ ¼åç¨±\n",
    "df.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(f\"âœ… CSV å·²æˆåŠŸå­˜å…¥ SQLite è³‡æ–™åº« {db_file} çš„ {table_name} è¡¨æ ¼\")\n",
    "\n",
    "# === 4. æ¸¬è©¦è®€å–å‰ 5 ç­†è³‡æ–™ ===\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"SELECT * FROM {table_name} LIMIT 5;\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "print(\"å‰ 5 ç­†è³‡æ–™ï¼š\")\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# === 5. é—œé–‰é€£ç·š ===\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c31981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U bitsandbytes rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0d3b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Danie\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# è¼‰å…¥æ‰€éœ€çš„å¥—ä»¶ï¼ˆPackagesï¼‰\n",
    "# Import necessary libraries\n",
    "\n",
    "import json                         # è™•ç† JSON æ ¼å¼è³‡æ–™çš„æ¨™æº–å¥—ä»¶ / Standard JSON library\n",
    "import torch                        # PyTorch æ˜¯ä¸€å€‹æ·±åº¦å­¸ç¿’æ¡†æ¶ / PyTorch deep learning framework\n",
    "from typing import List             # ç”¨ä¾†è¨»è§£ List å‹åˆ¥ / Type annotation for list\n",
    "from transformers import (          # Transformers æ¨¡å‹ç›¸é—œå‡½å¼åº« / HuggingFace Transformers library\n",
    "    AutoModelForCausalLM,           # è‡ªå‹•è¼‰å…¥å› æœèªè¨€æ¨¡å‹ / Auto loader for causal language models\n",
    "    AutoTokenizer,                  # è‡ªå‹•è¼‰å…¥å°æ‡‰çš„ tokenizer / Auto loader for tokenizer\n",
    "    BitsAndBytesConfig,             # ç”¨ä¾†è¨­å®šé‡åŒ–æ¨¡å‹çš„åƒæ•¸ / Configuration for model quantization\n",
    "    pipeline                        # æä¾›ç°¡å–®çš„æ¨¡å‹æ¨è«–ä»‹é¢ / Easy interface for model inference\n",
    ")\n",
    "from tqdm.autonotebook import tqdm  # é¡¯ç¤ºé€²åº¦æ¢ï¼ˆé©ç”¨æ–¼ Jupyter Notebookï¼‰ / Progress bar in Jupyter\n",
    "import jieba                        # ä¸­æ–‡æ–·è©å·¥å…· / Chinese word segmentation\n",
    "from rank_bm25 import BM25Okapi     # BM25 æœå°‹æ¨¡å‹ / BM25 retrieval model\n",
    "from sentence_transformers import SentenceTransformer  # å‘é‡æ¨¡å‹ / Sentence embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc99263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è£ç½®: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Exception in thread Thread-13 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa4 in position 7: invalid start byte\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78758bbbb9f48f0806757888607844a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»‹ç´¹ç¾½çƒè³½äº‹çš„é‡è¦ç´°ç¯€ï¼ŒåŒ…å«å°æ‰‹çš„è©³ç´°ç´¹ä»‹ã€æ¯”è³½çš„æµç¨‹å®‰æ’ã€ä»¥åŠæ¯”è³½çš„è¦å‰‡åŠé‡è¦è¦å‰‡è®Šå‹•ï¼Œä¸¦æä¾›è³½å¾Œåˆ†æï¼Œç¸½çµæ¯”è³½çµæœåŠå°ä¸‹è³½äº‹çš„å½±éŸ¿ã€‚\n",
      "\n",
      "**å…§å®¹æ¦‚è¦ï¼š**\n",
      "\n",
      "1.  **å°æ‰‹ä»‹ç´¹ï¼š**\n",
      "    *   å°æ‰‹åŸºæœ¬è³‡æ–™ï¼ˆå§“åã€åœ‹ç±ã€çƒé½¡ã€è·æ¥­æ’åã€æ“…é•·çƒç¨®ã€ç‰¹é»ï¼‰ï¼šä¾‹å¦‚ï¼Œ\"å¼µå°æ˜ï¼Œä¾†è‡ªä¸­åœ‹ï¼Œçƒé½¡10å¹´ï¼Œä¸–ç•Œæ’åç¬¬200åï¼Œæ“…é•·ç™¼çƒï¼Œå°é€Ÿåº¦å‹çƒè¼ƒæ•æ„Ÿ\"ã€‚\n",
      "    *   å°æ‰‹è¿‘æœŸè¡¨ç¾ï¼šè¿‘æœŸæ¯”è³½æˆç¸¾ã€å„ªåŠ£å‹¢åˆ†æã€è³½å‰ç‹€æ…‹è©•ä¼°ã€‚ä¾‹å¦‚ï¼Œ\"ä¸Šé€±åœ¨ä¸Šæµ·æ¯”è³½ï¼Œä»¥ä¸‰åˆ†å…©è² æ™‰ç´šï¼Œé›–ç„¶ç‹€æ…‹ä¸éŒ¯ï¼Œä½†å°å·¦æ‰‹ä½åå¼±ã€‚\"\n",
      "    *   å°æ‰‹è³½äº‹é¢¨æ ¼åŠå¼±é»ï¼šäº†è§£å°æ‰‹çš„æ‰“æ³•ç¿’æ…£ã€æ“…é•·èˆ‡ä¸æ“…é•·ï¼Œä»¥åŠå¯ä»¥åˆ©ç”¨çš„å¼±é»ã€‚ä¾‹å¦‚ï¼Œ\"å°è®Šé™£çƒåæ‡‰è¼ƒæ…¢ï¼Œå®¹æ˜“è¢«å¿«æ”»æ‰“äº‚ç¯€å¥\"ã€‚\n",
      "\n",
      "2.  **æ¯”è³½æµç¨‹ï¼š**\n",
      "    *   æ¯”è³½æ™‚é–“ã€åœ°é»ã€å ´åœ°ç‹€æ³ï¼šå¤©æ°£ã€å ´åœ°æè³ªã€å…‰ç·šç­‰å½±éŸ¿å› ç´ ã€‚\n",
      "    *   æ¯”è³½å½¢å¼ï¼ˆå–®æ‰“ã€é›™æ‰“ã€åœ˜é«”ï¼‰ï¼šæ˜é¡¯æŒ‡å‡ºæ¯”è³½ç¨®é¡ã€‚\n",
      "    *   æ¯”è³½åˆ†å±€åŠç¸½å±€ï¼šèªªæ˜æ¯å±€çš„å¾—åˆ†æ–¹å¼ï¼ˆ21åˆ†åˆ¶ï¼Œå…ˆ11åˆ†å‹ä¸€å±€ï¼Œä½†å±€æ•¸çš„å¾—åˆ†å¿…é ˆæ˜¯å¥‡æ•¸ï¼‰ï¼Œä»¥åŠå‹åˆ©æ¢ä»¶ã€‚\n",
      "    *   æ¯”è³½æ™‚é–“å®‰æ’ï¼ˆæ¯å±€çš„æ™‚é–“é™åˆ¶ã€ä¼‘æ¯æ™‚é–“ï¼‰ã€‚\n",
      "\n",
      "3.  **æ¯”è³½è¦å‰‡ï¼š**\n",
      "    *   åŸºæœ¬è¦å‰‡ï¼šå¾—åˆ†æ–¹å¼ã€ç™¼çƒè¦å‰‡ã€æœå‹™è¦å‰‡ã€ç ´ç™¼è¦å‰‡ã€æ¢å¾©çƒè¦å‰‡ã€ç¦å€è¦å‰‡ç­‰ã€‚\n",
      "    *   é‡è¦è¦å‰‡è®Šå‹•ï¼šè³½å‰æ˜¯å¦æœ‰é‡å°ç‰¹å®šè¦å‰‡é€²è¡Œèª¿æ•´ï¼Ÿä¾‹å¦‚ï¼Œè³½å‰æ˜¯å¦å…è¨±ä½¿ç”¨è† å¢Šï¼Ÿ\n",
      "    *   ç‰¹æ®Šè¦å‰‡ï¼šé‡å°ç‰¹æ®Šæƒ…æ³çš„è¦å‰‡ï¼Œä¾‹å¦‚ï¼šè£œè³½è¦å‰‡ã€å››å±€åŠè¦å‰‡ã€‚\n",
      "\n",
      "4.  **è¦å‰‡åŠé‡è¦è¦å‰‡è®Šå‹•ç´°ç¯€ï¼š**\n",
      "    *   è©³ç´°è§£é‡‹æ¯å€‹è¦å‰‡çš„ç´°ç¯€å’Œæ‡‰ç”¨å ´æ™¯ã€‚ä¾‹å¦‚ï¼šç™¼çƒæ™‚ï¼Œå¿…é ˆåœ¨æœå‹™ç·šä¸Šæ–¹ç™¼çƒï¼Œä¸”çƒå¿…é ˆè½åœ¨å°æ‰‹æœå‹™å€ã€‚\n",
      "    *   èªªæ˜è¦å‰‡è®Šå‹•å°æ¯”è³½çš„å½±éŸ¿ã€‚ä¾‹å¦‚ï¼šå…è¨±ä½¿ç”¨è† å¢Šï¼Œå¯èƒ½æœƒ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# ====== è¨­å®šé‡åŒ–åƒæ•¸ï¼Œæ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨ / Set quantization settings for smaller memory usage ======\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                    # ä½¿ç”¨ 4-bit æ¬Šé‡ / Use 4-bit weights\n",
    "    bnb_4bit_use_double_quant=True,       # å•Ÿç”¨é›™é‡é‡åŒ– / Enable double quantization\n",
    "    bnb_4bit_quant_type=\"nf4\",            # ä½¿ç”¨ nf4 é‡åŒ–é¡å‹ / Quantization type\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 # ä½¿ç”¨ bfloat16 é€²è¡Œè¨ˆç®— / Use bfloat16 for compute\n",
    ")\n",
    "\n",
    "# ====== æª¢æŸ¥ GPU ======\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ä½¿ç”¨è£ç½®: {device}\")\n",
    "\n",
    "# ====== è¼‰å…¥å¾®èª¿å¥½çš„èªè¨€æ¨¡å‹ï¼ˆGemmaï¼‰ / Load pretrained LLM ======\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"unsloth/gemma-3-4b-it\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",             # è‡ªå‹•åˆ†é…æ¨¡å‹åˆ° GPUï¼ˆæ”¯æ´å¤š GPUï¼‰\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# ====== è¼‰å…¥å°æ‡‰çš„ tokenizer / Load tokenizer for the model ======\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/gemma-3-4b-it\")\n",
    "\n",
    "# ====== ä½¿ç”¨ pipeline åŒ…è£æ¨¡å‹æ¨è«–ä»‹é¢ / Create a pipeline for generation ======\n",
    "llm_pipe = pipeline(\n",
    "    \"text-generation\",            # ä»»å‹™ç‚ºæ–‡æœ¬ç”Ÿæˆ / Task type\n",
    "    model=llm,                    # ä½¿ç”¨çš„æ¨¡å‹ / LLM\n",
    "    tokenizer=tokenizer,          # tokenizer\n",
    "    max_new_tokens=512,           # å›æ‡‰æœ€å¤§é•·åº¦ / Maximum new tokens\n",
    "    do_sample=False,              # ä¸ä½¿ç”¨éš¨æ©Ÿ samplingï¼ˆä½¿ç”¨è²ªå©ªè§£ç¢¼ï¼‰/ Greedy decoding\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    top_k=None,\n",
    "    device_map=\"auto\",            # è‡ªå‹•ä½¿ç”¨ GPU / Automatically use GPU\n",
    ")\n",
    "\n",
    "# ====== æ¸¬è©¦ç”Ÿæˆ ======\n",
    "prompt = \"ä»‹ç´¹ç¾½çƒ\"\n",
    "outputs = llm_pipe(prompt)\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234985f",
   "metadata": {},
   "source": [
    "ä½¿ç”¨RAGçµ¦å®šé å…ˆè¨­è¨ˆå¥½çš„ç°¡å–®å•é¡ŒåŠå°æ‡‰ä»£ç¢¼\n",
    "\n",
    "å¯èƒ½è¦æƒ³æƒ³çœ‹\n",
    "userå•é¡Œ: å‘¨å¤©æˆåœ¨ç¬¬ä¸€å±€ç”¨äº†å¹¾å€‹æ®ºçƒ?\n",
    "é€™ç¨®é™„æœ‰äººåçš„è©²å¦‚ä½•æ’°å¯«å•é¡Œé›†??\n",
    "é‚„æ˜¯æ‡‰è©²é€™æ¨£è™•ç†\n",
    "å•é¡Œé›†: æŸäººåœ¨ç¬¬ä¸€å±€ç”¨äº†å¹¾å€‹æ®ºçƒ?\n",
    "åŒ¹é…åˆ°å¾Œï¼Œå†æŠŠäººåå¡«é€²å»?(ä½¿ç”¨LLMå¹«å¿™å¡«å—?é‚„æ˜¯ç¨‹å¼ç¢¼åˆ¤æ–·å¡«å…¥?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c225b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "# è®€å– badminton.json\n",
    "with open(\"badminton_query_templates.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# å°‡ question ç•¶ä½œ chunk\n",
    "chunks = [item[\"question\"] for item in data]\n",
    "sql_template = [item[\"sql_template\"] for item in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b6c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Danie\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.422 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# å°æ¯å€‹ chunk æ–·è©\n",
    "tokenized_chunks = [list(jieba.cut(chunk)) for chunk in chunks]\n",
    "\n",
    "# å»ºç«‹ BM25 æ¨¡å‹\n",
    "bm25 = BM25Okapi(tokenized_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06f7677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237a7675532e4ade874273603028331a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# è¼‰å…¥å¤šèªè¨€ embedding æ¨¡å‹\n",
    "embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "# è¨ˆç®—æ¯å€‹ chunk çš„å‘é‡\n",
    "chunks_embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff36010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_retrieve(query: str, chunks: List[str], bm25: BM25Okapi) -> List[str]:\n",
    "    tokenized_query = list(jieba.cut(query))\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    rank = sorted(zip(chunks, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [chunk for chunk, _ in rank]\n",
    "\n",
    "def embedding_retrieve(query: str, chunks: List[str], chunks_embeddings: np.ndarray, embedding_model: SentenceTransformer) -> List[str]:\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦\n",
    "    scores = np.dot(chunks_embeddings, query_embedding) / (np.linalg.norm(chunks_embeddings, axis=1) * np.linalg.norm(query_embedding))\n",
    "    rank = sorted(zip(chunks, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [chunk for chunk, _ in rank]\n",
    "\n",
    "def reciprocal_rank_fusion(*ranked_lists, k=60) -> List[str]:\n",
    "    scores = {}\n",
    "    for rl in ranked_lists:\n",
    "        for rank, doc in enumerate(rl, start=1):\n",
    "            scores[doc] = scores.get(doc, 0.0) + 1.0 / (k + rank)\n",
    "    fused = sorted(scores.items(), key=lambda x: -x[1])\n",
    "    return [doc for doc, _ in fused]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59e850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 similar: é€™ä½é¸æ‰‹åœ¨å¤šæ•¸å›åˆä¸­ä¸»è¦ç«™åœ¨å“ªå€‹å ´å€ç™¼çƒæˆ–æ¥çƒï¼Ÿ\n",
      "åŒ¹é…åˆ°é¡åˆ¥: SELECT player_location_area, COUNT(*) AS freq FROM all_dataset WHERE server = '{player_name}' GROUP BY player_location_area ORDER BY freq DESC LIMIT 1;\n",
      "0.952892\n"
     ]
    }
   ],
   "source": [
    "#query = \"é€™ä½é¸æ‰‹å¤§å¤šç«™åœ¨å“ªè£¡ç™¼çƒï¼Ÿ\"\n",
    "query = input(\"è«‹è¼¸å…¥æ‚¨çš„æŸ¥è©¢å•é¡Œï¼š\")\n",
    "\n",
    "# å„æª¢ç´¢çµæœ\n",
    "bm25_ranked = bm25_retrieve(query, chunks, bm25)\n",
    "embedding_ranked = embedding_retrieve(query, chunks, chunks_embeddings, embedding_model)\n",
    "\n",
    "# èåˆ\n",
    "fused_ranked = reciprocal_rank_fusion(bm25_ranked, embedding_ranked)\n",
    "\n",
    "print(\"Top 1 similar:\", fused_ranked[0])\n",
    "\n",
    "top1 = fused_ranked[0]\n",
    "top1_idx = chunks.index(top1)\n",
    "similarity_score = np.dot(chunks_embeddings[top1_idx], embedding_model.encode(query)) / \\\n",
    "                   (np.linalg.norm(chunks_embeddings[top1_idx]) * np.linalg.norm(embedding_model.encode(query)))\n",
    "\n",
    "if similarity_score < 0.95:\n",
    "    print(\"ç„¡åŒ¹é…\")\n",
    "else:\n",
    "    print(\"åŒ¹é…åˆ°é¡åˆ¥:\", sql_template[top1_idx])\n",
    "    print(similarity_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead0427",
   "metadata": {},
   "source": [
    "è‹¥ä¸åŒ¹é…è©¢å•å°å‹LLMæ˜¯å¦å¯ä»¥åªç”¨SELECTå®Œæˆæ’°å¯«ç¨‹å¼ç¢¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb837cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§© LLM è¼¸å‡ºï¼š\n",
      "```sqlite\n",
      "SELECT player_location_area FROM badminton_data WHERE player = 'é¸æ‰‹å§“å'\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# === 1ï¸âƒ£ å®šç¾© JSON æª”æ¡ˆåç¨± ===\n",
    "json_file = \"column_definition.json\" # ä½ çš„ JSON æª”å\n",
    "\n",
    "# === 2ï¸âƒ£ è¼‰å…¥æ¬„ä½å®šç¾© JSON æª” ===\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_definitions = json.load(f)\n",
    "\n",
    "# å¾ JSON æª”ä¸­å–å¾— 'data_columns' éƒ¨åˆ†\n",
    "column_definitions = full_definitions.get(\"data_columns\", [])\n",
    "\n",
    "# Add a print statement to inspect the structure\n",
    "#print(\"--- è¼‰å…¥çš„ JSON å…§å®¹é¡å‹ ---\")\n",
    "#print(type(full_definitions))\n",
    "#print(\"\\n--- 'data_columns' å…§å®¹ ---\")\n",
    "#print(type(column_definitions))\n",
    "#print(column_definitions)\n",
    "\n",
    "# === 3ï¸âƒ£ å°‡æ¬„ä½å®šç¾©è½‰æˆæ–‡å­—èªªæ˜ ===\n",
    "# ç¢ºä¿ column_definitions æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œä¸”æ¯å€‹å…ƒç´ éƒ½æœ‰ 'column' å’Œ 'definition' éµ\n",
    "if isinstance(column_definitions, list) and all(isinstance(item, dict) and 'column' in item and 'definition' in item for item in column_definitions):\n",
    "    column_info_text = \"\\n\".join(\n",
    "        [f\"- {item['column']}: {item['definition']}\" for item in column_definitions]\n",
    "    )\n",
    "else:\n",
    "    column_info_text = \"éŒ¯èª¤ï¼š'data_columns' çš„æ ¼å¼ä¸ç¬¦åˆé æœŸã€‚\"\n",
    "\n",
    "\n",
    "# --- å®šç¾© System Prompt ---\n",
    "\n",
    "EXTENDED_SYSTEM_PROMPT = f\"\"\"\n",
    "You are an expert in badminton sports and data analysis.\n",
    "Below are the column names and their definitions for the data table. Please refer to these definitions when answering questions:\n",
    "\n",
    "{column_info_text}\n",
    "\n",
    "If the question cannot be answered using a single simple SELECT statement,\n",
    "respond exactly with: \"I can not help you.\" Otherwise, please write SQL code for the user to query in SQLite, avoiding instructions unrelated to the question.\n",
    "**important** Only provide SQL code\n",
    "\"\"\".strip()\n",
    "\n",
    "# --- å®šç¾©ä½¿ç”¨è€… Prompt æ¨¡æ¿ ---\n",
    "USER_PROMPT = \"\"\"\n",
    "### Question: \n",
    "{query}\n",
    "\"\"\".strip()\n",
    "\n",
    "# --- å‡è¨­ä½¿ç”¨è€…è¼¸å…¥ ---\n",
    "#query = \"æŸ¥è©¢ç¬¬ä¸€å±€ç¬¬ä¸€å›åˆçš„æœ€çµ‚æ¯”æ•¸\"\n",
    "#query = \"å‘Šè¨´æˆ‘CHOU Tien Chenåœ¨ç¬¬ä¸€å±€ä½¿ç”¨å¹¾å€‹æ®ºçƒ\"\n",
    "#query = input(\"è«‹è¼¸å…¥æ‚¨çš„æŸ¥è©¢å•é¡Œï¼š\")\n",
    "\n",
    "# --- å»ºç«‹èŠå¤©æ ¼å¼ ---\n",
    "chats = [\n",
    "    {\"role\": \"system\", \"content\": EXTENDED_SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT.format(query=query)}\n",
    "]\n",
    "\n",
    "# --- å‘¼å«å°æ¨¡å‹ï¼ˆGemma-3-4B-itï¼‰ ---\n",
    "response = llm_pipe(chats)[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "# --- è¼¸å‡ºçµæœ ---\n",
    "print(\"ğŸ§© LLM è¼¸å‡ºï¼š\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
