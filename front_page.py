import streamlit as st
import os
import io
import platform
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
import zipfile # <--- å¼•å…¥å¿…è¦çš„æ¨¡çµ„

# è‡ªè¨‚æ¨¡çµ„
from config.prompts import create_system_prompt
from utils.data_loader import load_all_data
from utils.ai_client import initialize_client

# --- åˆå§‹è¨­å®šèˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥ ---
load_dotenv()

# è¨­å®šé é¢
st.set_page_config(
    page_title="ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«",
    page_icon="ğŸ¸",
    layout="wide"
)

# --- è³‡æ–™è¼‰å…¥ ---
df, data_schema_info, column_definitions_info = load_all_data()


# --- Streamlit UI ä»‹é¢ ---
st.title("ğŸ¸ ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«")
st.markdown("#### é€éè‡ªç„¶èªè¨€ï¼Œç›´æ¥ç”Ÿæˆæ•¸æ“šåˆ†æåœ–è¡¨")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("âš™ï¸ API è¨­å®š")
    api_mode = st.selectbox("API æ¨¡å¼", ["Gemini", "OpenAI å®˜æ–¹", "äº¤å¤§ä¼ºæœå™¨"], index=0)

    api_key_env_var = "GEMINI_API_KEY" if api_mode == "Gemini" else "OPENAI_API_KEY"
    api_key_input = st.text_input(
        f"{api_mode} API Key",
        value=os.getenv(api_key_env_var, ""),
        type="password"
    )

    if api_mode == "Gemini":
        model_choice = st.selectbox("é¸æ“‡æ¨¡å‹", ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"], index=0)
    else:
        model_choice = st.selectbox("é¸æ“‡æ¨¡å‹", ["gpt-4o-mini", "gpt-4o"], index=0)

    st.divider()
    st.markdown("#### ç¯„ä¾‹å•é¡Œ")
    st.info("""
    - çƒå“¡ A çš„å„çƒç¨®åˆ†ä½ˆæ˜¯æ€éº¼æ¨£çš„ï¼Ÿè«‹ç”¨åœ“é¤…åœ–å‘ˆç¾ã€‚
    - å“ªå€‹è½é» (`landing_zone`) çš„çƒæœ€å¸¸å‡ºç¾ï¼Ÿè«‹ç”¨é•·æ¢åœ–è¡¨ç¤ºã€‚
    - å„çƒå“¡ (`player`) çš„æ®ºçƒ (`smash`) æ¬¡æ•¸æ¯”è¼ƒã€‚
    - èª°æ˜¯å¤±èª¤ç‹ï¼Ÿè«‹çµ±è¨ˆå„çƒå“¡çš„å¤±èª¤æ¬¡æ•¸ã€‚
    """)
    
    st.divider()

    # --- START: å…¨æ–°ä¿®æ”¹çš„å„²å­˜å°è©±åŠŸèƒ½ ---
    # æº–å‚™ä¸€å€‹è¨˜æ†¶é«”å…§çš„ BytesIO ç‰©ä»¶ä¾†å­˜æ”¾ ZIP æª”æ¡ˆ
    zip_buffer = io.BytesIO()

    # æª¢æŸ¥æ˜¯å¦æœ‰å°è©±ç´€éŒ„å¯ä»¥å„²å­˜
    has_messages = "messages" in st.session_state and st.session_state.messages
    
    if has_messages:
        # ä½¿ç”¨ 'with' é™³è¿°å¼ä¾†å®‰å…¨åœ°å»ºç«‹ ZIP æª”æ¡ˆ
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_f:
            markdown_content = f"# ğŸ¸ ç¾½çƒ AI æ•¸æ“šåˆ†æå¸« - åˆ†æå ±å‘Š\n"
            markdown_content += f"**å„²å­˜æ™‚é–“:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n---\n\n"
            
            chart_counter = 0

            for message in st.session_state.messages:
                role_emoji = "ğŸ‘¤" if message["role"] == "user" else "ğŸ¤–"
                role_title = "ä½¿ç”¨è€…æå•" if message["role"] == "user" else "AI åˆ†æå¸«å›è¦†"
                
                content_to_save = message["content"]

                # å¦‚æœæ˜¯ AI çš„å›è¦†ï¼Œå°±ç§»é™¤ç¨‹å¼ç¢¼å€å¡Š
                if message["role"] == "assistant" and "```python" in content_to_save:
                    parts = content_to_save.split("```python")
                    before_code = parts[0]
                    after_code_parts = parts[1].split("```", 1)
                    after_code = after_code_parts[1] if len(after_code_parts) > 1 else ""
                    content_to_save = before_code + after_code
                
                markdown_content += f"### {role_emoji} {role_title}\n"
                markdown_content += f"{content_to_save.strip()}\n\n"
                
                # å¦‚æœè¨Šæ¯ä¸­æœ‰åœ–è¡¨ï¼Œå°‡å…¶å­˜å…¥ ZIP ä¸¦åœ¨ Markdown ä¸­å¼•ç”¨
                if message.get("figure") is not None:
                    chart_counter += 1
                    chart_filename = f"chart_{chart_counter}.png"
                    
                    # å°‡åœ–è¡¨å­˜å…¥ä¸€å€‹è¨˜æ†¶é«”å…§çš„ buffer
                    img_buffer = io.BytesIO()
                    message["figure"].savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
                    img_buffer.seek(0)
                    
                    # å°‡åœ–è¡¨çš„ byte å¯«å…¥ ZIP æª”æ¡ˆ
                    zip_f.writestr(chart_filename, img_buffer.getvalue())
                    
                    # åœ¨ Markdown å…§å®¹ä¸­åŠ å…¥åœ–ç‰‡çš„å¼•ç”¨
                    markdown_content += f"![ç”¢ç”Ÿçš„åœ–è¡¨ {chart_counter}]({chart_filename})\n\n"

                markdown_content += "---\n\n"
            
            # æœ€å¾Œï¼Œå°‡æ•´ç†å¥½çš„ Markdown æ–‡å­—å…§å®¹å¯«å…¥ ZIP æª”æ¡ˆä¸­
            zip_f.writestr("åˆ†æå ±å‘Š.md", markdown_content.encode('utf-8'))

    st.download_button(
       label="ğŸ’¾ ä¸‹è¼‰åˆ†æå ±å‘Š (ZIP)",
       data=zip_buffer.getvalue(),
       file_name=f"ç¾½çƒåˆ†æå ±å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
       mime="application/zip",
       disabled=not has_messages, # å¦‚æœæ²’æœ‰å°è©±ç´€éŒ„ï¼Œå‰‡ç¦ç”¨æŒ‰éˆ•
       help="é»æ­¤å¯å°‡åœ–æ–‡ä¸¦èŒ‚çš„åˆ†æå ±å‘Šä¸‹è¼‰ç‚º ZIP å£“ç¸®æª”"
    )
    # --- END: å…¨æ–°ä¿®æ”¹çš„å„²å­˜å°è©±åŠŸèƒ½ ---

    # æ¸…é™¤å°è©±æŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±"):
        st.session_state.messages = []
        st.rerun()

# åˆå§‹åŒ– AI client
client = initialize_client(api_mode, api_key_input)

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºå°è©±æ­·å²
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "figure" in message and message["figure"] is not None:
            st.pyplot(message["figure"])
            buf = io.BytesIO()
            message["figure"].savefig(buf, format='png', dpi=300, bbox_inches='tight')
            buf.seek(0)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰åœ–è¡¨",
                data=buf,
                file_name=f"ç¾½çƒåˆ†æ_{idx}_{datetime.now().strftime('%Y%m%d')}.png",
                mime="image/png",
                key=f"download_history_{idx}",
                use_container_width=False
            )

# --- ä¸»å°è©±æµç¨‹ ---
if prompt := st.chat_input("è«‹è¼¸å…¥ä½ çš„æ•¸æ“šåˆ†æå•é¡Œ..."):
    if df is None:
        st.error("éŒ¯èª¤ï¼šç„¡æ³•é€²è¡Œåˆ†æï¼Œå› ç‚º 'all_dataset.csv' æª”æ¡ˆä¸å­˜åœ¨æˆ–ç„¡æ³•è®€å–ã€‚")
    elif not api_key_input:
        st.error("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¼¸å…¥æ‚¨çš„ API Keyã€‚")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("AI æ•¸æ“šåˆ†æå¸«æ­£åœ¨æ€è€ƒä¸­..."):
                try:
                    # æ­¥é©Ÿ 1: ç¬¬ä¸€æ¬¡ AI å‘¼å«ï¼ˆåŠ å…¥å°è©±æ­·å²ï¼‰
                    system_prompt = create_system_prompt(data_schema_info, column_definitions_info)

                    # å»ºç«‹å®Œæ•´çš„å°è©±æ­·å²ï¼ˆåŒ…å« system + æ‰€æœ‰æ­·å²è¨Šæ¯ï¼‰
                    conversation_messages = [{"role": "system", "content": system_prompt}]

                    # åŠ å…¥æ‰€æœ‰æ­·å²å°è©±ï¼ˆä½†æ’é™¤åœ–è¡¨è³‡è¨Šï¼Œåªä¿ç•™æ–‡å­—ï¼‰
                    for msg in st.session_state.messages:
                        conversation_messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })

                    response = client.chat.completions.create(
                        model=model_choice,
                        messages=conversation_messages,
                    )
                    ai_response_text = response.choices[0].message.content
                    
                    code_to_execute = None
                    if "```python" in ai_response_text:
                        code_start = ai_response_text.find("```python") + len("```python\n")
                        code_end = ai_response_text.rfind("```")
                        code_to_execute = ai_response_text[code_start:code_end].strip()

                    # æ­¥é©Ÿ 2: åŸ·è¡Œç¨‹å¼ç¢¼
                    final_fig = None
                    summary_data = None
                    if code_to_execute:
                        exec_globals = {
                            "pd": pd, "st": st, "df": df.copy(),
                            "platform": platform, "io": io
                        }
                        exec(code_to_execute, exec_globals)
                        final_fig = exec_globals.get('fig', None)
                        
                        for var_name, var_value in exec_globals.items():
                            if isinstance(var_value, (pd.DataFrame, pd.Series)) and var_name != 'df':
                                summary_data = var_value
                                break
                    
                    # æ­¥é©Ÿ 3: ç¬¬äºŒæ¬¡ AI å‘¼å« (ç”Ÿæˆæ´å¯Ÿ)
                    summary_text = ""
                    if summary_data is not None:
                        with st.spinner("AI æ­£åœ¨åˆ†ææ•¸æ“šä¸¦ç”Ÿæˆæ–‡å­—æ´å¯Ÿ..."):
                            try:
                                table_markdown = summary_data.to_markdown()
                                insight_prompt = f"""
                                é€™æ˜¯åŸå§‹çš„ä½¿ç”¨è€…å•é¡Œ: "{prompt}"
                                é€™æ˜¯æ ¹æ“šå•é¡Œè¨ˆç®—å‡ºçš„æ‘˜è¦è¡¨æ ¼:
                                ```markdown
                                {table_markdown}
                                ```
                                è«‹æ‰®æ¼”å°ˆæ¥­æ•¸æ“šåˆ†æå¸«ï¼Œæ ¹æ“šæ­¤è¡¨æ ¼ï¼Œç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ä¸€æ®µç°¡çŸ­ç²¾é—¢çš„æ•¸æ“šæ´å¯Ÿã€‚
                                ç›´æ¥æä¾›çµè«–ï¼Œä¸è¦è¤‡è¿°å•é¡Œæˆ–ç¨‹å¼ç¢¼ã€‚
                                """
                                # ä¸è¦åŠ å…¥å°è©±æ­·å²ï¼Œåªå°ˆæ³¨æ–¼ç•¶å‰çš„è¡¨æ ¼åˆ†æ
                                insight_response = client.chat.completions.create(
                                    model=model_choice,
                                    messages=[
                                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ•¸æ“šåˆ†æå¸«ï¼Œå°ˆé–€å¾æ•¸æ“šè¡¨æ ¼ä¸­è§£è®€å‡ºæœ‰åƒ¹å€¼çš„æ´å¯Ÿã€‚è«‹åªåˆ†ææä¾›çš„è¡¨æ ¼æ•¸æ“šï¼Œç”¨ç¹é«”ä¸­æ–‡ç°¡æ½”èªªæ˜é‡é»ã€‚"},
                                        {"role": "user", "content": insight_prompt}
                                    ],
                                    temperature=0.3,  # é™ä½æº«åº¦ï¼Œè®“å›ç­”æ›´ä¸€è‡´
                                )
                                summary_text = insight_response.choices[0].message.content
                            except Exception as e:
                                summary_text = f"\n\n*(ç„¡æ³•è‡ªå‹•ç”Ÿæˆæ•¸æ“šæ´å¯Ÿ: {e})*"

                    # æ­¥é©Ÿ 4: æ•´åˆçµæœä¸¦é¡¯ç¤º
                    final_content = ai_response_text
                    if summary_text:
                        final_content += f"\n\n---\n#### ğŸ“Š æ•¸æ“šæ´å¯Ÿ\n{summary_text}"
                    
                    st.markdown(final_content)
                    if code_to_execute:
                        with st.expander("é»æ­¤æŸ¥çœ‹ AI ç”Ÿæˆçš„ Python ç¨‹å¼ç¢¼"):
                            st.code(code_to_execute, language="python")

                    if final_fig:
                        st.pyplot(final_fig)
                        buf = io.BytesIO()
                        final_fig.savefig(buf, format='png', dpi=300, bbox_inches='tight')
                        buf.seek(0)
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰åœ–è¡¨",
                            data=buf,
                            file_name=f"ç¾½çƒåˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                            mime="image/png",
                            use_container_width=False
                        )
                    elif code_to_execute and not final_fig:
                         st.warning("AI ç”Ÿæˆçš„ç¨‹å¼ç¢¼å·²åŸ·è¡Œï¼Œä½†æœªæ‰¾åˆ°åç‚º `fig` çš„åœ–è¡¨ç‰©ä»¶ã€‚")

                    # æ­¥é©Ÿ 5: å­˜å…¥ session state
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": final_content,
                        "figure": final_fig
                    })

                except Exception as e:
                    st.error(f"è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    st.session_state.messages.append({"role": "assistant", "content": str(e), "figure": None})