import streamlit as st
import openai
import os
import pandas as pd
import json
import io
from dotenv import load_dotenv

# --- åˆå§‹è¨­å®šèˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥ ---
load_dotenv()

# è¨­å®šé é¢
st.set_page_config(
    page_title="ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«",
    page_icon="ğŸ¸",
    layout="wide"
)

# --- è³‡æ–™è¼‰å…¥èˆ‡å¿«å– ---
DATA_FILE = "all_dataset.csv"
COLUMN_DEFINITION_FILE = "column_definition.json"

@st.cache_data
def load_data(filepath):
    """è¼‰å…¥ CSV æ•¸æ“šä¸¦å¿«å–"""
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    return None

@st.cache_data
def get_data_schema(df):
    """å¾ DataFrame ç²å–æ¬„ä½å‹æ…‹è³‡è¨Š"""
    buffer = io.StringIO()
    df.info(buf=buffer)
    return buffer.getvalue()

@st.cache_data
def load_column_definitions(filepath):
    """è¼‰å…¥ä¸¦æ ¼å¼åŒ–æ¬„ä½å®šç¾©"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            full_definitions = json.load(f)
        
        column_definitions = full_definitions.get("data_columns", [])
        
        if isinstance(column_definitions, list) and all(
            isinstance(item, dict) and 'column' in item and 'definition' in item
            for item in column_definitions
        ):
            return "\n".join(
                [f"- `{item['column']}`: {item['definition']}" for item in column_definitions]
            )
        else:
            return "éŒ¯èª¤ï¼š'column_definition.json' çš„ 'data_columns' æ ¼å¼ä¸ç¬¦åˆé æœŸã€‚"
    except FileNotFoundError:
        return "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° 'column_definition.json' æª”æ¡ˆã€‚"
    except json.JSONDecodeError:
        return "éŒ¯èª¤ï¼š'column_definition.json' æª”æ¡ˆæ ¼å¼éŒ¯èª¤ã€‚"

# è¼‰å…¥è³‡æ–™
df = load_data(DATA_FILE)
if df is not None:
    data_schema_info = get_data_schema(df)
    column_definitions_info = load_column_definitions(COLUMN_DEFINITION_FILE)
else:
    data_schema_info = "éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° `all_dataset.csv`ï¼Œè«‹å…ˆæº–å‚™å¥½æ•¸æ“šæª”æ¡ˆã€‚"
    column_definitions_info = load_column_definitions(COLUMN_DEFINITION_FILE)


# --- System Prompt ç”¢ç”Ÿå™¨ ---
def create_system_prompt():
    """å»ºç«‹çµ¦ LLM çš„ç³»çµ±æŒ‡ä»¤"""
    return f"""
ä½ æ˜¯ä¸€ä½é ‚å°–çš„ç¾½çƒæ•¸æ“šç§‘å­¸å®¶ã€‚
ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šä½¿ç”¨è€…æå‡ºçš„å•é¡Œï¼Œç”Ÿæˆä¸€æ®µ Python ç¨‹å¼ç¢¼ä¾†åˆ†æä¸€å€‹å·²ç¶“è¼‰å…¥çš„ pandas DataFrame `df`ï¼Œä¸¦ç¹ªè£½å‡ºèƒ½å›ç­”è©²å•é¡Œçš„è¦–è¦ºåŒ–åœ–è¡¨ã€‚

**æ•¸æ“šè³‡è¨Š:**
1.  **DataFrame Schema (è³‡æ–™æ¬„ä½èˆ‡å‹æ…‹):**
{data_schema_info}
2.  **æ¬„ä½å®šç¾©:**
{column_definitions_info}

**ä½ çš„ç¨‹å¼ç¢¼å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡:**
1.  ç¨‹å¼ç¢¼å¿…é ˆä½¿ç”¨ `matplotlib` æˆ– `seaborn` å‡½å¼åº«ä¾†ç¹ªåœ–ã€‚
2.  **çµ•å°ä¸è¦** åŒ…å« `pd.read_csv()` æˆ–ä»»ä½•è®€å–è³‡æ–™çš„ç¨‹å¼ç¢¼ï¼Œå› ç‚º `df` å·²ç¶“å­˜åœ¨æ–¼åŸ·è¡Œç’°å¢ƒä¸­ã€‚
3.  ç¨‹å¼ç¢¼çš„æœ€çµ‚çµæœ**å¿…é ˆ**æ˜¯ä¸€å€‹ Matplotlib çš„ Figure ç‰©ä»¶ï¼Œä¸¦å°‡å…¶è³¦å€¼çµ¦ä¸€å€‹åç‚º `fig` çš„è®Šæ•¸ã€‚ä¾‹å¦‚ï¼š`fig, ax = plt.subplots()`ã€‚
4.  **çµ•å°ä¸è¦** åœ¨ç¨‹å¼ç¢¼ä¸­ä½¿ç”¨ `plt.show()`ï¼ŒStreamlit æœƒè² è²¬è™•ç†åœ–è¡¨çš„é¡¯ç¤ºã€‚
5.  åœ¨ç¨‹å¼ç¢¼ä¸­å¦¥å–„è™•ç†ä¸­æ–‡å­—é«”é¡¯ç¤ºå•é¡Œï¼Œä½¿ç”¨ `plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']` æˆ–å…¶ä»–åˆé©çš„å­—é«”è¨­å®šã€‚
6.  ä½ çš„å›è¦†æ‡‰åŒ…å«å…©å€‹éƒ¨åˆ†ï¼š
    -   ä¸€å€‹ç°¡çŸ­çš„æ–‡å­—èªªæ˜ï¼Œè§£é‡‹ä½ å°‡å¦‚ä½•åˆ†æä»¥åŠåœ–è¡¨çš„æ„æ¶µã€‚
    -   ä¸€å€‹ Python ç¨‹å¼ç¢¼å€å¡Š (```python ... ```)ï¼Œå…¶ä¸­åŒ…å«ç¹ªåœ–ç¨‹å¼ç¢¼ã€‚
"""

# --- AI Client åˆå§‹åŒ– ---
# (é€™éƒ¨åˆ†èˆ‡æ‚¨åŸæœ¬çš„ç¨‹å¼ç¢¼ç›¸åŒ)
def initialize_client(api_mode, api_key):
    """æ ¹æ“šæ¨¡å¼å’Œé‡‘é‘°åˆå§‹åŒ– AI client"""
    if api_mode == "Gemini":
        return openai.OpenAI(
            api_key=api_key,
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
        )
    elif api_mode == "äº¤å¤§ä¼ºæœå™¨":
        return openai.OpenAI(
            api_key=api_key,
            base_url="https://llm.nycu-adsl.cc"
        )
    else:  # OpenAI å®˜æ–¹
        return openai.OpenAI(api_key=api_key)


# --- Streamlit UI ä»‹é¢ ---
st.title("ğŸ¸ ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«")
st.markdown("#### é€éè‡ªç„¶èªè¨€ï¼Œç›´æ¥ç”Ÿæˆæ•¸æ“šåˆ†æåœ–è¡¨")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("âš™ï¸ API è¨­å®š")
    api_mode = st.selectbox("API æ¨¡å¼", ["Gemini", "OpenAI å®˜æ–¹", "äº¤å¤§ä¼ºæœå™¨"], index=0)

    api_key_env_var = "GEMINI_API_KEY" if api_mode == "Gemini" else "OPENAI_API_KEY"
    api_key_input = st.text_input(
        f"{api_mode} API Key",
        value=os.getenv(api_key_env_var, ""),
        type="password"
    )

    if api_mode == "Gemini":
        model_choice = st.selectbox("é¸æ“‡æ¨¡å‹", ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"], index=0)
    else:
        model_choice = st.selectbox("é¸æ“‡æ¨¡å‹", ["gpt-4o-mini", "gpt-4o"], index=0)

    st.divider()
    st.markdown("#### ç¯„ä¾‹å•é¡Œ")
    st.info("""
    - çƒå“¡ A çš„å„çƒç¨®åˆ†ä½ˆæ˜¯æ€éº¼æ¨£çš„ï¼Ÿè«‹ç”¨åœ“é¤…åœ–å‘ˆç¾ã€‚
    - å“ªå€‹è½é» (`landing_zone`) çš„çƒæœ€å¸¸å‡ºç¾ï¼Ÿè«‹ç”¨é•·æ¢åœ–è¡¨ç¤ºã€‚
    - å„çƒå“¡ (`player`) çš„æ®ºçƒ (`smash`) æ¬¡æ•¸æ¯”è¼ƒã€‚
    - èª°æ˜¯å¤±èª¤ç‹ï¼Ÿè«‹çµ±è¨ˆå„çƒå“¡çš„å¤±èª¤æ¬¡æ•¸ã€‚
    """)

# åˆå§‹åŒ– AI client
client = initialize_client(api_mode, api_key_input)

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºå°è©±æ­·å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "figure" in message and message["figure"] is not None:
            st.pyplot(message["figure"])


# --- ä¸»å°è©±æµç¨‹ ---
if prompt := st.chat_input("è«‹è¼¸å…¥ä½ çš„æ•¸æ“šåˆ†æå•é¡Œ..."):
    if df is None:
        st.error("éŒ¯èª¤ï¼šç„¡æ³•é€²è¡Œåˆ†æï¼Œå› ç‚º 'all_dataset.csv' æª”æ¡ˆä¸å­˜åœ¨æˆ–ç„¡æ³•è®€å–ã€‚")
    elif not api_key_input:
        st.error("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¼¸å…¥æ‚¨çš„ API Keyã€‚")
    else:
        # å°‡ä½¿ç”¨è€…å•é¡ŒåŠ å…¥æ­·å²ç´€éŒ„ä¸¦é¡¯ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # æº–å‚™å‘¼å« API
        with st.chat_message("assistant"):
            with st.spinner("AI æ•¸æ“šåˆ†æå¸«æ­£åœ¨ç”Ÿæˆç¨‹å¼ç¢¼ä¸¦ç¹ªè£½åœ–è¡¨ä¸­..."):
                try:
                    system_prompt = create_system_prompt()
                    
                    response = client.chat.completions.create(
                        model=model_choice,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": prompt}
                        ],
                    )
                    
                    ai_response_text = response.choices[0].message.content
                    
                    # å¾ AI å›æ‡‰ä¸­è§£æç¨‹å¼ç¢¼
                    code_to_execute = None
                    if "```python" in ai_response_text:
                        code_start = ai_response_text.find("```python") + len("```python\n")
                        code_end = ai_response_text.rfind("```")
                        code_to_execute = ai_response_text[code_start:code_end].strip()

                    # é¡¯ç¤º AI çš„æ–‡å­—èªªæ˜
                    st.markdown(ai_response_text)
                    
                    final_fig = None
                    if code_to_execute:
                        # é¡¯ç¤ºå³å°‡åŸ·è¡Œçš„ç¨‹å¼ç¢¼
                        with st.expander("é»æ­¤æŸ¥çœ‹ AI ç”Ÿæˆçš„ Python ç¨‹å¼ç¢¼"):
                            st.code(code_to_execute, language="python")
                        
                        # å»ºç«‹ä¸€å€‹å®‰å…¨çš„åŸ·è¡Œç’°å¢ƒ
                        exec_globals = {
                            "pd": pd,
                            "st": st,
                            "df": df.copy() # ä½¿ç”¨å‰¯æœ¬ä»¥é˜²æ„å¤–ä¿®æ”¹
                        }
                        
                        # åŸ·è¡Œç¨‹å¼ç¢¼
                        exec(code_to_execute, exec_globals)
                        
                        # å¾åŸ·è¡Œç’°å¢ƒä¸­ç²å–åœ–è¡¨ç‰©ä»¶
                        if 'fig' in exec_globals:
                            final_fig = exec_globals['fig']
                            st.pyplot(final_fig)
                        else:
                            st.warning("AI ç”Ÿæˆçš„ç¨‹å¼ç¢¼ä¸­æœªæ‰¾åˆ°åç‚º `fig` çš„åœ–è¡¨ç‰©ä»¶ã€‚")

                    # å°‡å®Œæ•´çµæœå­˜å…¥ session state
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_response_text,
                        "figure": final_fig
                    })

                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    st.session_state.messages.append({"role": "assistant", "content": str(e), "figure": None})

# æ¸…é™¤å°è©±æŒ‰éˆ•
if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±"):
    st.session_state.messages = []
    st.rerun()
