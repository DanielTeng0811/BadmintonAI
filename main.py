import streamlit as st
import io
from dotenv import load_dotenv
from datetime import datetime

# è‡ªè¨‚æ¨¡çµ„
from utils.data_loader import load_all_data
from utils.ai_client import initialize_client
from components.sidebar import render_sidebar
from logic.analysis_flow import process_user_query

# --- åˆå§‹è¨­å®šèˆ‡ç’°å¢ƒè®Šæ•¸è¼‰å…¥ ---
load_dotenv()

# è¨­å®šé é¢ (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ st æŒ‡ä»¤)
st.set_page_config(
    page_title="ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«",
    page_icon="ğŸ¸",
    layout="wide"
)

# --- è³‡æ–™è¼‰å…¥ ---
df, data_schema_info, column_definitions_info = load_all_data()

# --- Streamlit UI ---
st.title("ğŸ¸ ç¾½çƒ AI æ•¸æ“šåˆ†æå¸«")
st.markdown("#### é€éè‡ªç„¶èªè¨€ï¼Œç›´æ¥ç”Ÿæˆæ•¸æ“šåˆ†æåœ–è¡¨")

# --- æ¸²æŸ“å´é‚Šæ¬„ ---
settings = render_sidebar()
# è§£åŒ…è¨­å®š
api_mode = settings.get("api_mode", "OpenAI å®˜æ–¹")
api_key_input = settings.get("api_key_input", "")
model_choice = settings.get("model_choice", "gpt-4o")
enable_clarification = settings.get("enable_clarification", False)

# åˆå§‹åŒ– client
client = initialize_client(api_mode, api_key_input)

# --- åˆå§‹åŒ– Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "awaiting_clarification" not in st.session_state:
    st.session_state.awaiting_clarification = False
if "clarification_data" not in st.session_state:
    st.session_state.clarification_data = None
if "original_prompt" not in st.session_state:
    st.session_state.original_prompt = ""

# --- é¡¯ç¤ºæ­·å²å°è©± ---
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # è‹¥æœ‰å„ªåŒ–å¾Œçš„æå•é‚è¼¯ï¼Œé¡¯ç¤ºåœ¨å°è©±ä¸­
        if message.get("enhanced_prompt"):
            with st.expander("ğŸ§  æŸ¥çœ‹ AI å„ªåŒ–å¾Œçš„æå•é‚è¼¯ (Step 1)", expanded=False):
                st.markdown(f"**å„ªåŒ–å°å¼• (Enhanced Prompt):**\n{message['enhanced_prompt']}")

        st.markdown(message["content"])
        figures = message.get("figures", [])
        if not figures and message.get("figure"):
            figures = [message["figure"]]

        for fig_idx, fig in enumerate(figures):
            st.pyplot(fig)
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=300, bbox_inches='tight')
            buf.seek(0)
            st.download_button(
                label=f"ğŸ“¥ ä¸‹è¼‰åœ–è¡¨ {fig_idx + 1}",
                data=buf,
                file_name=f"ç¾½çƒåˆ†æ_{idx}_{fig_idx}_{datetime.now().strftime('%Y%m%d')}.png",
                mime="image/png",
                key=f"download_history_{idx}_{fig_idx}",
            )

# --- ä¸»å°è©±æµç¨‹ ---
use_history = st.toggle("ğŸ”— æ¥çºŒå‰æ–‡ (Track History)", value=False, help="é–‹å•Ÿå¾Œï¼ŒAI å°‡åƒè€ƒæœ€è¿‘çš„å°è©±ç´€éŒ„ä¾†å›ç­”å•é¡Œã€‚")

if prompt := st.chat_input("è«‹è¼¸å…¥ä½ çš„æ•¸æ“šåˆ†æå•é¡Œ..."):
    # Clear debug log on new input
    with open("llm_debug_log.txt", "w", encoding="utf-8") as f:
        pass 

    if df is None:
        st.error("âŒ æ‰¾ä¸åˆ° 'all_dataset.csv'ã€‚")
    elif not api_key_input:
        st.error("âš ï¸ è«‹è¼¸å…¥ API Keyã€‚")
    else:
        # === è™•ç†æ¾„æ¸…å›æ‡‰ ===
        skip_clarification = False
        if st.session_state.awaiting_clarification:
            # ä½¿ç”¨è€…å·²ç¶“é¸æ“‡äº†é¸é …æˆ–æä¾›è£œå……èªªæ˜
            user_answer = prompt.strip()
            clarification_data = st.session_state.clarification_data

            # æª¢æŸ¥æ˜¯å¦æ˜¯é¸é …ç·¨è™Ÿ
            if user_answer.isdigit() and clarification_data:
                option_index = int(user_answer) - 1
                if 0 <= option_index < len(clarification_data.get('options', [])):
                    user_answer = clarification_data['options'][option_index]

            # çµ„åˆå®Œæ•´å•é¡Œ
            full_prompt = f"{st.session_state.original_prompt}\nè£œå……èªªæ˜: {user_answer}"

            # è¨˜éŒ„ä½¿ç”¨è€…çš„è£œå……å›æ‡‰
            st.session_state.messages.append({"role": "user", "content": prompt})

            # é‡ç½®æ¾„æ¸…ç‹€æ…‹
            st.session_state.awaiting_clarification = False
            st.session_state.clarification_data = None

            # ä½¿ç”¨å®Œæ•´å•é¡Œé€²è¡Œåˆ†æ
            prompt = full_prompt
            # é€™è£¡æˆ‘å€‘ä¸è¨­å®š skip_clarification è®Šæ•¸çµ¦ analysis_flow (å› ç‚ºå®ƒå…§éƒ¨æ²’æœ‰åƒæ•¸æ¥æ”¶)
            # ä½†æˆ‘å€‘å¯ä»¥é€é prompt å…§å®¹ (åŒ…å« "è£œå……èªªæ˜") è®“ analysis_flow å…§éƒ¨çš„åˆ¤æ–·æ©Ÿåˆ¶è·³éæª¢æŸ¥
            # (åœ¨ analysis_flow.py Line 45 `if "è£œå……èªªæ˜:" in prompt: skip_clarification_check = True`)
        else:
            # å„²å­˜å•é¡Œèˆ‡è¿½è¹¤ç‹€æ…‹
            st.session_state.messages.append({
                "role": "user", 
                "content": prompt,
                "tracked": use_history 
            })

        # å‘¼å«é‚è¼¯è™•ç†æ ¸å¿ƒ
        process_user_query(
            prompt=prompt,
            client=client,
            model_choice=model_choice,
            df=df,
            data_schema_info=data_schema_info,
            enable_clarification=enable_clarification,
            use_history=use_history
        )
